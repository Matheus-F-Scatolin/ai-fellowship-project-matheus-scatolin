{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99d77e1",
   "metadata": {},
   "source": [
    "# PDF Text Extraction with LLM Integration\n",
    "\n",
    "This notebook demonstrates a comprehensive approach to extracting structured data from PDF documents, specifically focusing on OAB (Brazilian Bar Association) cards and system screens. We'll combine traditional text extraction methods with modern LLM integration for robust document processing.\n",
    "\n",
    "## Objectives:\n",
    "- Extract text from PDFs using multiple libraries\n",
    "- Apply heuristic and regex-based extraction\n",
    "- Use Named Entity Recognition (NER) \n",
    "- Integrate with OpenAI's LLM for intelligent extraction\n",
    "- Build a complete extraction pipeline with validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23bd4c3",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "First, let's install all the required packages for our PDF extraction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fd65e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (0.11.7)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.5-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting camelot\n",
      "  Downloading Camelot-12.06.29.tar.gz (3.5 MB)\n",
      "     ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 1.6/3.5 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.4/3.5 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.5/3.5 MB 8.3 MB/s  0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting openai\n",
      "  Using cached openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from pdfplumber) (12.0.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from pdfplumber) (5.0.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (46.0.3)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp310-cp310-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic)\n",
      "  Downloading pydantic_core-2.41.4-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from pydantic) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.4.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-2.0.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema)\n",
      "  Downloading rpds_py-0.28.0-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting SQLAlchemy<0.8.0,>=0.7.7 (from camelot)\n",
      "  Downloading SQLAlchemy-0.7.10.tar.gz (3.5 MB)\n",
      "     ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "     ----------------------- ---------------- 2.1/3.5 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.5/3.5 MB 9.5 MB/s  0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting Elixir>=0.7.1 (from camelot)\n",
      "  Downloading Elixir-0.7.1.tar.gz (47 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sqlalchemy-migrate>=0.7.1 (from camelot)\n",
      "  Downloading sqlalchemy_migrate-0.13.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting chardet>=1.0.1 (from camelot)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting xlwt==0.7.2 (from camelot)\n",
      "  Downloading xlwt-0.7.2.zip (131 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting xlrd==0.7.1 (from camelot)\n",
      "  Downloading xlrd-0.7.1.zip (125 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.11.1-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pbr>=1.8 (from sqlalchemy-migrate>=0.7.1->camelot)\n",
      "  Downloading pbr-7.0.3-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is looking at multiple versions of sqlalchemy-migrate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sqlalchemy-migrate>=0.7.1 (from camelot)\n",
      "  Downloading sqlalchemy_migrate-0.12.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading sqlalchemy-migrate-0.11.0.tar.gz (128 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: decorator in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (5.2.1)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\mathe\\onedrive\\documentos\\enter\\ai-fellowship-project-matheus-scatolin\\.conda\\lib\\site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (1.17.0)\n",
      "Collecting sqlparse (from sqlalchemy-migrate>=0.7.1->camelot)\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Tempita>=0.4 (from sqlalchemy-migrate>=0.7.1->camelot)\n",
      "  Downloading Tempita-0.6.0-py3-none-any.whl.metadata (972 bytes)\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.9 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.7/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.1/12.9 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.9 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 10.9 MB/s  0:00:01\n",
      "Using cached pymupdf-1.26.5-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Downloading spacy-3.8.7-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/14.9 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/14.9 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.3/14.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.7/14.9 MB 11.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 11.0 MB/s  0:00:01\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.2 MB/s  0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp310-cp310-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp310-cp310-win_amd64.whl (117 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp310-cp310-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.3/632.3 kB 7.9 MB/s  0:00:00\n",
      "Downloading thinc-8.3.6-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 9.6 MB/s  0:00:00\n",
      "Downloading blis-1.3.0-cp310-cp310-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.4/6.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 10.7 MB/s  0:00:00\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Using cached smart_open-7.4.3-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.1-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading marisa_trie-1.3.1-cp310-cp310-win_amd64.whl (143 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.28.0-cp310-cp310-win_amd64.whl (223 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached pbr-7.0.3-py2.py3-none-any.whl (131 kB)\n",
      "Downloading Tempita-0.6.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading wrapt-2.0.0-cp310-cp310-win_amd64.whl (60 kB)\n",
      "Building wheels for collected packages: camelot, xlrd, xlwt, SQLAlchemy, Elixir, sqlalchemy-migrate\n",
      "  Building wheel for camelot (setup.py): started\n",
      "  Building wheel for camelot (setup.py): finished with status 'done'\n",
      "  Created wheel for camelot: filename=camelot-12.6.29-py3-none-any.whl size=3926712 sha256=af4823d1ef4e3d04a892952429239c9ebad56f2077bc6dd2b1753d4a9a0e1ba1\n",
      "  Stored in directory: c:\\users\\mathe\\appdata\\local\\pip\\cache\\wheels\\1d\\69\\7f\\2f89658f102e77c90bf032bb7fcd995a5fe28cc7ad17a1adcb\n",
      "  Building wheel for xlrd (setup.py): started\n",
      "  Building wheel for xlrd (setup.py): finished with status 'done'\n",
      "  Created wheel for xlrd: filename=xlrd-0.7.1-py3-none-any.whl size=118032 sha256=886cbe3019401845093215dd678672df47979ffb9fcede1ae4f7612ee4d005dd\n",
      "  Stored in directory: c:\\users\\mathe\\appdata\\local\\pip\\cache\\wheels\\25\\95\\16\\bb70d4a4ffd0d0ac1a8d9dfb85f337a55a1767de6c204c61d7\n",
      "  Building wheel for xlwt (setup.py): started\n",
      "  Building wheel for xlwt (setup.py): finished with status 'done'\n",
      "  Created wheel for xlwt: filename=xlwt-0.7.2-py3-none-any.whl size=121758 sha256=5d511637d1c23636edc39cfe8b9aa15058d702196db5502c4c3ad84450cec200\n",
      "  Stored in directory: c:\\users\\mathe\\appdata\\local\\pip\\cache\\wheels\\4a\\12\\59\\8d068757a81ce3638fb93c3c8cef9fd556f8adc2e39c743689\n",
      "  Building wheel for SQLAlchemy (setup.py): started\n",
      "  Building wheel for SQLAlchemy (setup.py): finished with status 'done'\n",
      "  Created wheel for SQLAlchemy: filename=sqlalchemy-0.7.10-py3-none-any.whl size=696392 sha256=75a34b49226432f042beacba7462a4e91f1230e61dd21b3296c75a7ff564ff94\n",
      "  Stored in directory: c:\\users\\mathe\\appdata\\local\\pip\\cache\\wheels\\77\\bf\\65\\e625ae1c6c3076adeab170ebba39a92033996375fe1b174e76\n",
      "  Building wheel for Elixir (setup.py): started\n",
      "  Building wheel for Elixir (setup.py): finished with status 'done'\n",
      "  Created wheel for Elixir: filename=elixir-0.7.1-py3-none-any.whl size=53949 sha256=3d0d86c87aba3f239cf89acf97c8dd99685fe13d35ec398ab289f3e2bca4bf86\n",
      "  Stored in directory: c:\\users\\mathe\\appdata\\local\\pip\\cache\\wheels\\7e\\b7\\93\\ce0bc7895c0d1a289689c122ad630846323083fb4182072429\n",
      "  Building wheel for sqlalchemy-migrate (setup.py): started\n",
      "  Building wheel for sqlalchemy-migrate (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlalchemy-migrate: filename=sqlalchemy_migrate-0.11.0-py3-none-any.whl size=108971 sha256=9cd7812f9436ddc9f5fd1dd19e1b35974cacd5ae73a852d659554fc819291ab5\n",
      "  Stored in directory: c:\\users\\mathe\\appdata\\local\\pip\\cache\\wheels\\df\\6f\\ea\\3a14b4d70c042b9a28f8ef4ba2954b63f1371a148717c64969\n",
      "Successfully built camelot xlrd xlwt SQLAlchemy Elixir sqlalchemy-migrate\n",
      "Installing collected packages: xlwt, xlrd, Tempita, SQLAlchemy, cymem, wrapt, wasabi, urllib3, typing-inspection, tqdm, sqlparse, spacy-loggers, spacy-legacy, sniffio, shellingham, rpds-py, python-dotenv, pymupdf, pydantic-core, pbr, numpy, murmurhash, mdurl, MarkupSafe, marisa-trie, jiter, idna, h11, Elixir, distro, cloudpathlib, click, chardet, certifi, catalogue, attrs, annotated-types, srsly, sqlalchemy-migrate, smart-open, requests, referencing, pydantic, preshed, markdown-it-py, language-data, jinja2, httpcore, blis, anyio, rich, langcodes, jsonschema-specifications, httpx, confection, camelot, typer, thinc, openai, jsonschema, weasel, spacy\n",
      "\n",
      "   ----------------------------------------  0/62 [xlwt]\n",
      "   ----------------------------------------  0/62 [xlwt]\n",
      "   ----------------------------------------  0/62 [xlwt]\n",
      "   ----------------------------------------  0/62 [xlwt]\n",
      "    ---------------------------------------  1/62 [xlrd]\n",
      "    ---------------------------------------  1/62 [xlrd]\n",
      "    ---------------------------------------  1/62 [xlrd]\n",
      "   - --------------------------------------  2/62 [Tempita]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   - --------------------------------------  3/62 [SQLAlchemy]\n",
      "   --- ------------------------------------  5/62 [wrapt]\n",
      "   --- ------------------------------------  5/62 [wrapt]\n",
      "   --- ------------------------------------  5/62 [wrapt]\n",
      "   --- ------------------------------------  6/62 [wasabi]\n",
      "   --- ------------------------------------  6/62 [wasabi]\n",
      "   --- ------------------------------------  6/62 [wasabi]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ---- -----------------------------------  7/62 [urllib3]\n",
      "   ----- ----------------------------------  8/62 [typing-inspection]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ----- ----------------------------------  9/62 [tqdm]\n",
      "   ------ --------------------------------- 10/62 [sqlparse]\n",
      "   ------ --------------------------------- 10/62 [sqlparse]\n",
      "   ------ --------------------------------- 10/62 [sqlparse]\n",
      "   ------ --------------------------------- 10/62 [sqlparse]\n",
      "   ------ --------------------------------- 10/62 [sqlparse]\n",
      "   ------ --------------------------------- 10/62 [sqlparse]\n",
      "   ------- -------------------------------- 11/62 [spacy-loggers]\n",
      "   ------- -------------------------------- 11/62 [spacy-loggers]\n",
      "   ------- -------------------------------- 11/62 [spacy-loggers]\n",
      "   ------- -------------------------------- 12/62 [spacy-legacy]\n",
      "   ------- -------------------------------- 12/62 [spacy-legacy]\n",
      "   ------- -------------------------------- 12/62 [spacy-legacy]\n",
      "   -------- ------------------------------- 13/62 [sniffio]\n",
      "   --------- ------------------------------ 14/62 [shellingham]\n",
      "   --------- ------------------------------ 14/62 [shellingham]\n",
      "   ---------- ----------------------------- 16/62 [python-dotenv]\n",
      "   ---------- ----------------------------- 16/62 [python-dotenv]\n",
      "   ---------- ----------------------------- 16/62 [python-dotenv]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ---------- ----------------------------- 17/62 [pymupdf]\n",
      "   ----------- ---------------------------- 18/62 [pydantic-core]\n",
      "   ----------- ---------------------------- 18/62 [pydantic-core]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 19/62 [pbr]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------ --------------------------- 20/62 [numpy]\n",
      "   ------------- -------------------------- 21/62 [murmurhash]\n",
      "   -------------- ------------------------- 22/62 [mdurl]\n",
      "   -------------- ------------------------- 23/62 [MarkupSafe]\n",
      "   ---------------- ----------------------- 26/62 [idna]\n",
      "   ---------------- ----------------------- 26/62 [idna]\n",
      "   ---------------- ----------------------- 26/62 [idna]\n",
      "   ----------------- ---------------------- 27/62 [h11]\n",
      "   ----------------- ---------------------- 27/62 [h11]\n",
      "   ----------------- ---------------------- 27/62 [h11]\n",
      "   ------------------ --------------------- 28/62 [Elixir]\n",
      "   ------------------ --------------------- 28/62 [Elixir]\n",
      "   ------------------ --------------------- 29/62 [distro]\n",
      "   ------------------ --------------------- 29/62 [distro]\n",
      "   ------------------- -------------------- 30/62 [cloudpathlib]\n",
      "   ------------------- -------------------- 30/62 [cloudpathlib]\n",
      "   ------------------- -------------------- 30/62 [cloudpathlib]\n",
      "   ------------------- -------------------- 30/62 [cloudpathlib]\n",
      "   ------------------- -------------------- 30/62 [cloudpathlib]\n",
      "   ------------------- -------------------- 30/62 [cloudpathlib]\n",
      "   -------------------- ------------------- 31/62 [click]\n",
      "   -------------------- ------------------- 31/62 [click]\n",
      "   -------------------- ------------------- 31/62 [click]\n",
      "   -------------------- ------------------- 31/62 [click]\n",
      "   -------------------- ------------------- 31/62 [click]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   -------------------- ------------------- 32/62 [chardet]\n",
      "   --------------------- ------------------ 33/62 [certifi]\n",
      "   --------------------- ------------------ 34/62 [catalogue]\n",
      "   ---------------------- ----------------- 35/62 [attrs]\n",
      "   ---------------------- ----------------- 35/62 [attrs]\n",
      "   ---------------------- ----------------- 35/62 [attrs]\n",
      "   ---------------------- ----------------- 35/62 [attrs]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ----------------------- ---------------- 37/62 [srsly]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------ --------------- 38/62 [sqlalchemy-migrate]\n",
      "   ------------------------- -------------- 39/62 [smart-open]\n",
      "   ------------------------- -------------- 39/62 [smart-open]\n",
      "   ------------------------- -------------- 39/62 [smart-open]\n",
      "   ------------------------- -------------- 39/62 [smart-open]\n",
      "   ------------------------- -------------- 40/62 [requests]\n",
      "   ------------------------- -------------- 40/62 [requests]\n",
      "   ------------------------- -------------- 40/62 [requests]\n",
      "   -------------------------- ------------- 41/62 [referencing]\n",
      "   -------------------------- ------------- 41/62 [referencing]\n",
      "   -------------------------- ------------- 41/62 [referencing]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 42/62 [pydantic]\n",
      "   --------------------------- ------------ 43/62 [preshed]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ---------------------------- ----------- 44/62 [markdown-it-py]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 45/62 [language-data]\n",
      "   ----------------------------- ---------- 46/62 [jinja2]\n",
      "   ----------------------------- ---------- 46/62 [jinja2]\n",
      "   ----------------------------- ---------- 46/62 [jinja2]\n",
      "   ----------------------------- ---------- 46/62 [jinja2]\n",
      "   ----------------------------- ---------- 46/62 [jinja2]\n",
      "   ----------------------------- ---------- 46/62 [jinja2]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 47/62 [httpcore]\n",
      "   ------------------------------ --------- 48/62 [blis]\n",
      "   ------------------------------ --------- 48/62 [blis]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   ------------------------------- -------- 49/62 [anyio]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 50/62 [rich]\n",
      "   -------------------------------- ------- 51/62 [langcodes]\n",
      "   -------------------------------- ------- 51/62 [langcodes]\n",
      "   -------------------------------- ------- 51/62 [langcodes]\n",
      "   --------------------------------- ------ 52/62 [jsonschema-specifications]\n",
      "   ---------------------------------- ----- 53/62 [httpx]\n",
      "   ---------------------------------- ----- 53/62 [httpx]\n",
      "   ---------------------------------- ----- 53/62 [httpx]\n",
      "   ---------------------------------- ----- 53/62 [httpx]\n",
      "   ---------------------------------- ----- 53/62 [httpx]\n",
      "   ---------------------------------- ----- 53/62 [httpx]\n",
      "   ---------------------------------- ----- 54/62 [confection]\n",
      "   ---------------------------------- ----- 54/62 [confection]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ----------------------------------- ---- 55/62 [camelot]\n",
      "   ------------------------------------ --- 56/62 [typer]\n",
      "   ------------------------------------ --- 56/62 [typer]\n",
      "   ------------------------------------ --- 56/62 [typer]\n",
      "   ------------------------------------ --- 56/62 [typer]\n",
      "   ------------------------------------ --- 56/62 [typer]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------ --- 57/62 [thinc]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   ------------------------------------- -- 58/62 [openai]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 59/62 [jsonschema]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   -------------------------------------- - 60/62 [weasel]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------  61/62 [spacy]\n",
      "   ---------------------------------------- 62/62 [spacy]\n",
      "\n",
      "Successfully installed Elixir-0.7.1 MarkupSafe-3.0.3 SQLAlchemy-0.7.10 Tempita-0.6.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 blis-1.3.0 camelot-12.6.29 catalogue-2.0.10 certifi-2025.10.5 chardet-5.2.0 click-8.3.0 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.11 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jinja2-3.1.6 jiter-0.11.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 numpy-2.2.6 openai-2.7.1 pbr-7.0.3 preshed-3.0.10 pydantic-2.12.3 pydantic-core-2.41.4 pymupdf-1.26.5 python-dotenv-1.2.1 referencing-0.37.0 requests-2.32.5 rich-14.2.0 rpds-py-0.28.0 shellingham-1.5.4 smart-open-7.4.3 sniffio-1.3.1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-migrate-0.11.0 sqlparse-0.5.3 srsly-2.5.1 thinc-8.3.6 tqdm-4.67.1 typer-0.20.0 typing-inspection-0.4.2 urllib3-2.5.0 wasabi-1.1.3 weasel-0.4.1 wrapt-2.0.0 xlrd-0.7.1 xlwt-0.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'camelot' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'camelot'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'xlrd' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'xlrd'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'xlwt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'xlwt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'SQLAlchemy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'SQLAlchemy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'Elixir' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'Elixir'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'sqlalchemy-migrate' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sqlalchemy-migrate'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber numpy pymupdf spacy pydantic jsonschema camelot openai python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47dd0d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.1/12.8 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.5/12.8 MB 11.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 10.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 11.0/12.8 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 10.6 MB/s  0:00:01\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c510bd",
   "metadata": {},
   "source": [
    "## 2. Setup and Load Dataset\n",
    "\n",
    "Let's import the necessary libraries and load our dataset configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723437ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List\n",
    "import pdfplumber\n",
    "import fitz  # PyMuPDF\n",
    "import spacy\n",
    "from pydantic import BaseModel, create_model, Field\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('./files', exist_ok=True)\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "print(\" Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f54c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset loaded successfully! Found 6 entries:\n",
      "  1. Label: carteira_oab, PDF: oab_1.pdf\n",
      "  2. Label: carteira_oab, PDF: oab_2.pdf\n",
      "  3. Label: carteira_oab, PDF: oab_3.pdf\n",
      "  4. Label: tela_sistema, PDF: tela_sistema_1.pdf\n",
      "  5. Label: tela_sistema, PDF: tela_sistema_2.pdf\n",
      "  6. Label: tela_sistema, PDF: tela_sistema_3.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load dataset configuration\n",
    "try:\n",
    "    with open('./dataset.json', 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    print(f\" Dataset loaded successfully! Found {len(dataset)} entries:\")\n",
    "    for i, entry in enumerate(dataset):\n",
    "        print(f\"  {i+1}. Label: {entry['label']}, PDF: {entry['pdf_path']}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\" dataset.json not found in current directory\")\n",
    "    dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792a7798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found PDF: ./files/oab_1.pdf\n",
      " File size: 822.75 KB\n",
      " Number of pages: 1\n",
      " Page size (first page): 1056 x 552\n"
     ]
    }
   ],
   "source": [
    "# Check for PDF files and show metadata for the first one\n",
    "pdf_path = './files/oab_1.pdf'\n",
    "\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\" Found PDF: {pdf_path}\")\n",
    "    \n",
    "    # Get file metadata\n",
    "    file_stats = os.stat(pdf_path)\n",
    "    print(f\" File size: {file_stats.st_size / 1024:.2f} KB\")\n",
    "    \n",
    "    # Use pdfplumber to get PDF metadata\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        print(f\" Number of pages: {len(pdf.pages)}\")\n",
    "        print(f\" Page size (first page): {pdf.pages[0].width} x {pdf.pages[0].height}\")\n",
    "        \n",
    "        # Show metadata if available\n",
    "        if pdf.metadata:\n",
    "            print(\" PDF Metadata:\")\n",
    "            for key, value in pdf.metadata.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\" PDF file not found: {pdf_path}\")\n",
    "    print(\"Please ensure the PDF files are in the './files/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae26d74",
   "metadata": {},
   "source": [
    "## 3. Basic PDF Extraction with pdfplumber\n",
    "\n",
    "Let's extract text and words with their coordinates from the first page using pdfplumber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8595a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text (first 500 characters):\n",
      "JOANA D'ARC\n",
      "Inscrio Seccional Subseo\n",
      "101943 PR CONSELHO SECCIONAL - PARAN\n",
      "SUPLEMENTAR\n",
      "Endereo Profissional\n",
      "AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista\n",
      "SO PAULO - SP\n",
      "01310300\n",
      "Telefone Profissional\n",
      "SITUAO REGULAR\n",
      "\n",
      "==================================================\n",
      "\n",
      " First 10 words with coordinates:\n",
      "  1. 'JOANA' at (5.0, 13.0, 88.3, 38.0)\n",
      "  2. 'D'ARC' at (95.3, 13.0, 170.9, 38.0)\n",
      "  3. 'Inscrio' at (5.0, 120.6, 85.0, 140.6)\n",
      "  4. 'Seccional' at (156.0, 120.4, 238.4, 139.4)\n",
      "  5. 'Subseo' at (305.0, 120.6, 393.9, 140.6)\n",
      "  6. '101943' at (8.0, 151.8, 64.7, 168.8)\n",
      "  7. 'PR' at (156.0, 152.5, 178.2, 168.5)\n",
      "  8. 'CONSELHO' at (305.0, 150.8, 400.4, 167.8)\n",
      "  9. 'SECCIONAL' at (405.1, 150.8, 503.4, 167.8)\n",
      "  10. '-' at (508.1, 150.8, 513.8, 167.8)\n"
     ]
    }
   ],
   "source": [
    "def extract_text_pdfplumber(pdf_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract text using pdfplumber with coordinates.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        return {\"error\": f\"File not found: {pdf_path}\"}\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            first_page = pdf.pages[0]\n",
    "            \n",
    "            # Extract plain text\n",
    "            text = first_page.extract_text()\n",
    "            \n",
    "            # Extract words with coordinates\n",
    "            words = first_page.extract_words()\n",
    "\n",
    "            # Extract table data (if any)\n",
    "            tables = first_page.extract_tables()\n",
    "            \n",
    "            return {\n",
    "                \"text\": text,\n",
    "                \"words\": words,\n",
    "                \"tables\": tables,\n",
    "                \"page_size\": (first_page.width, first_page.height)\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error extracting with pdfplumber: {str(e)}\"}\n",
    "\n",
    "# Demonstrate extraction\n",
    "result = extract_text_pdfplumber('./files/oab_1.pdf')\n",
    "\n",
    "if \"error\" not in result:\n",
    "    print(\" Extracted text (first 500 characters):\")\n",
    "    print(result[\"text\"][:500] + \"...\" if len(result[\"text\"]) > 500 else result[\"text\"])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\" First 10 words with coordinates:\")\n",
    "    for i, word in enumerate(result[\"words\"][:10]):\n",
    "        print(f\"  {i+1}. '{word['text']}' at ({word['x0']:.1f}, {word['top']:.1f}, {word['x1']:.1f}, {word['bottom']:.1f})\")\n",
    "else:\n",
    "    print(f\" {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad13e3b",
   "metadata": {},
   "source": [
    "## 4. PDF Extraction with PyMuPDF (fitz)\n",
    "\n",
    "Now let's compare the results using PyMuPDF, which often provides better text extraction and bounding box information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d17f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyMuPDF extracted text (first 500 characters):\n",
      "JOANA D'ARC\n",
      "Inscrio\n",
      "Seccional\n",
      "Subseo\n",
      "101943\n",
      "PR\n",
      "CONSELHO SECCIONAL - PARAN\n",
      "SUPLEMENTAR\n",
      "Endereo Profissional\n",
      "AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista\n",
      "SO PAULO - SP\n",
      "01310300\n",
      "Telefone Profissional\n",
      "SITUAO REGULAR\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      " First 10 words with bounding boxes (PyMuPDF):\n",
      "  1. 'JOANA D'ARC' at (5.0, 6.0, 170.9, 40.3) - Font: Helvetica\n",
      "  2. 'Inscrio' at (5.0, 115.0, 85.0, 142.5) - Font: Helvetica\n",
      "  3. 'Seccional' at (156.0, 115.0, 238.4, 141.1) - Font: Helvetica\n",
      "  4. 'Subseo' at (305.0, 115.0, 393.9, 142.5) - Font: Helvetica\n",
      "  5. '101943' at (8.0, 147.0, 64.7, 170.4) - Font: Helvetica\n",
      "  6. 'PR' at (156.0, 148.0, 178.2, 170.0) - Font: Helvetica\n",
      "  7. 'CONSELHO SECCIONAL - PARAN' at (305.0, 146.0, 588.4, 169.4) - Font: Helvetica\n",
      "  8. 'SUPLEMENTAR' at (6.0, 180.0, 133.5, 203.4) - Font: Helvetica\n",
      "  9. 'Endereo Profissional' at (6.0, 230.0, 190.8, 256.1) - Font: Helvetica\n",
      "  10. 'AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista' at (6.0, 262.0, 422.3, 285.4) - Font: Helvetica\n",
      "\n",
      " Comparison:\n",
      "  pdfplumber words count: 31\n",
      "  PyMuPDF words count: 14\n",
      "  PyMuPDF provides additional font information and may handle complex layouts better\n"
     ]
    }
   ],
   "source": [
    "def extract_text_pymupdf(pdf_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract text using PyMuPDF with bounding boxes.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        return {\"error\": f\"File not found: {pdf_path}\"}\n",
    "    \n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    first_page = doc[0]\n",
    "    page_size = first_page.rect\n",
    "    # Extract plain text\n",
    "    text = first_page.get_text()\n",
    "    \n",
    "    # Extract text with detailed information\n",
    "    text_dict = first_page.get_text(\"dict\")\n",
    "    \n",
    "    # Extract words with bounding boxes\n",
    "    words = []\n",
    "    for block in text_dict[\"blocks\"]:\n",
    "        if \"lines\" in block:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    words.append({\n",
    "                        \"text\": span[\"text\"],\n",
    "                        \"bbox\": span[\"bbox\"],  # (x0, y0, x1, y1)\n",
    "                        \"font\": span[\"font\"],\n",
    "                        \"size\": span[\"size\"]\n",
    "                    })\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"words\": words,\n",
    "        \"page_size\": (page_size.width, page_size.height)\n",
    "    }\n",
    "\n",
    "\n",
    "# Demonstrate extraction\n",
    "fitz_result = extract_text_pymupdf('./files/oab_1.pdf')\n",
    "\n",
    "if \"error\" not in fitz_result:\n",
    "    print(\" PyMuPDF extracted text (first 500 characters):\")\n",
    "    print(fitz_result[\"text\"][:500] + \"...\" if len(fitz_result[\"text\"]) > 500 else fitz_result[\"text\"])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\" First 10 words with bounding boxes (PyMuPDF):\")\n",
    "    for i, word in enumerate(fitz_result[\"words\"][:10]):\n",
    "        if word[\"text\"].strip():  # Skip empty text\n",
    "            bbox = word[\"bbox\"]\n",
    "            print(f\"  {i+1}. '{word['text']}' at ({bbox[0]:.1f}, {bbox[1]:.1f}, {bbox[2]:.1f}, {bbox[3]:.1f}) - Font: {word['font']}\")\n",
    "    \n",
    "    print(\"\\n Comparison:\")\n",
    "    print(f\"  pdfplumber words count: {len(result.get('words', []))}\")\n",
    "    print(f\"  PyMuPDF words count: {len([w for w in fitz_result['words'] if w['text'].strip()])}\")\n",
    "    print(\"  PyMuPDF provides additional font information and may handle complex layouts better\")\n",
    "    \n",
    "else:\n",
    "    print(f\" {fitz_result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1e17a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyMuPDF extracted text (first 500 characters):\n",
      "LUIS FILIPE ARAUJO AMARAL\n",
      "Inscrio\n",
      "Seccional\n",
      "Subseo\n",
      "101943\n",
      "PR\n",
      "CONSELHO SECCIONAL - PARAN\n",
      "SUPLEMENTAR\n",
      "Endereo Profissional\n",
      "AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista\n",
      "SO PAULO - SP\n",
      "01310300\n",
      "Telefone Profissional\n",
      "SITUAO REGULAR\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      " First 10 words with bounding boxes (PyMuPDF):\n",
      "  1. 'LUIS FILIPE ARAUJO AMARAL' at (10.0, 6.0, 338.5, 37.6) - Font: Helvetica\n",
      "  2. 'Inscrio' at (5.0, 115.0, 85.0, 142.5) - Font: Helvetica\n",
      "  3. 'Seccional' at (154.0, 115.0, 236.4, 141.1) - Font: Helvetica\n",
      "  4. 'Subseo' at (303.0, 115.0, 391.9, 142.5) - Font: Helvetica\n",
      "  5. '101943' at (6.0, 147.0, 62.7, 170.4) - Font: Helvetica\n",
      "  6. 'PR' at (156.0, 147.0, 179.6, 170.4) - Font: Helvetica\n",
      "  7. 'CONSELHO SECCIONAL - PARAN' at (304.0, 146.0, 604.1, 170.7) - Font: Helvetica\n",
      "  8. 'SUPLEMENTAR' at (6.0, 181.0, 133.5, 204.4) - Font: Helvetica\n",
      "  9. 'Endereo Profissional' at (6.0, 229.0, 190.8, 255.1) - Font: Helvetica\n",
      "  10. 'AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista' at (5.0, 261.0, 470.2, 287.1) - Font: Helvetica\n",
      "\n",
      " Comparison:\n",
      "  pdfplumber words count: 0\n",
      "  PyMuPDF words count: 14\n",
      "  PyMuPDF provides additional font information and may handle complex layouts better\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate extraction\n",
    "fitz_result = extract_text_pymupdf('./files/oab_2.pdf')\n",
    "\n",
    "if \"error\" not in fitz_result:\n",
    "    print(\" PyMuPDF extracted text (first 500 characters):\")\n",
    "    print(fitz_result[\"text\"][:500] + \"...\" if len(fitz_result[\"text\"]) > 500 else fitz_result[\"text\"])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\" First 10 words with bounding boxes (PyMuPDF):\")\n",
    "    for i, word in enumerate(fitz_result[\"words\"][:10]):\n",
    "        if word[\"text\"].strip():  # Skip empty text\n",
    "            bbox = word[\"bbox\"]\n",
    "            print(f\"  {i+1}. '{word['text']}' at ({bbox[0]:.1f}, {bbox[1]:.1f}, {bbox[2]:.1f}, {bbox[3]:.1f}) - Font: {word['font']}\")\n",
    "    \n",
    "    print(\"\\n Comparison:\")\n",
    "    print(f\"  pdfplumber words count: {len(result.get('words', []))}\")\n",
    "    print(f\"  PyMuPDF words count: {len([w for w in fitz_result['words'] if w['text'].strip()])}\")\n",
    "    print(\"  PyMuPDF provides additional font information and may handle complex layouts better\")\n",
    "    \n",
    "else:\n",
    "    print(f\" {fitz_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983a5ed",
   "metadata": {},
   "source": [
    "## 5. Heuristic Text Extraction with Regex\n",
    "\n",
    "Let's create regex-based functions to extract specific fields from OAB documents based on common patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0265e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing regex extraction on sample text:\n",
      "  Nome: SUPLEMENTAR\n",
      "  Inscrio: 2300\n",
      "  Telefone: None\n",
      "  Seccional: None\n",
      "  Situao: REGULAR\n",
      "\n",
      " Sample text for reference:\n",
      "JOANA D'ARC\n",
      "Inscrio Seccional Subseo\n",
      "101943 PR CONSELHO SECCIONAL - PARAN\n",
      "SUPLEMENTAR\n",
      "Endereo Profissional\n",
      "AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista\n",
      "SO PAULO - SP\n",
      "01310300\n",
      "Telefone Profissional\n",
      "SITUAO REGULAR\n"
     ]
    }
   ],
   "source": [
    "def extract_nome(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract name from text (usually after 'Nome:' label).\"\"\"\n",
    "    patterns = [\n",
    "        r'Nome[:\\s]+([A-Z\\s]+?)(?:\\n|Inscrio|$)',\n",
    "        r'NOME[:\\s]+([A-Z\\s]+?)(?:\\n|INSCRIO|$)',\n",
    "        # Look for capitalized names at the beginning\n",
    "        r'^([A-Z\\s]{10,50}?)(?:\\n|Inscrio)',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.MULTILINE | re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def extract_inscricao(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract registration number (typically 4-6 digits).\"\"\"\n",
    "    patterns = [\n",
    "        r'Inscrio[:\\s]*(\\d{4,6})',\n",
    "        r'INSCRIO[:\\s]*(\\d{4,6})',\n",
    "        r'N[:\\s]*(\\d{4,6})',\n",
    "        r'N[:\\s]*(\\d{4,6})',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_telefone(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract Brazilian phone number.\"\"\"\n",
    "    patterns = [\n",
    "        r'(?:Tel|Telefone|Fone)[:\\s]*(\\(\\d{2}\\)\\s*\\d{4,5}-?\\d{4})',\n",
    "        r'(\\(\\d{2}\\)\\s*\\d{4,5}-?\\d{4})',\n",
    "        r'(\\d{2}\\s*\\d{4,5}-?\\d{4})',\n",
    "        r'Tel[:\\s]*(\\d{2}\\s*\\d{8,9})',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_seccional(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract seccional (2-letter state code).\"\"\"\n",
    "    patterns = [\n",
    "        r'Seccional[:\\s]*([A-Z]{2})',\n",
    "        r'SECCIONAL[:\\s]*([A-Z]{2})',\n",
    "        r'OAB[/\\s]*([A-Z]{2})',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_situacao(text: str) -> Optional[str]:\n",
    "    \"\"\"Extract professional status.\"\"\"\n",
    "    patterns = [\n",
    "        r'Situao[:\\s]*((?:Regular|Irregular|Suspenso|Ativo|Inativo)[^\\n]*)',\n",
    "        r'SITUAO[:\\s]*((?:REGULAR|IRREGULAR|SUSPENSO|ATIVO|INATIVO)[^\\n]*)',\n",
    "        r'(Situao\\s+Regular)',\n",
    "        r'(REGULAR|IRREGULAR|SUSPENSO|ATIVO|INATIVO)',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# Test our extraction functions\n",
    "sample_text = result.get(\"text\", \"\") if \"error\" not in result else \"\"\n",
    "\n",
    "if sample_text:\n",
    "    print(\" Testing regex extraction on sample text:\")\n",
    "    print(f\"  Nome: {extract_nome(sample_text)}\")\n",
    "    print(f\"  Inscrio: {extract_inscricao(sample_text)}\")\n",
    "    print(f\"  Telefone: {extract_telefone(sample_text)}\")\n",
    "    print(f\"  Seccional: {extract_seccional(sample_text)}\")\n",
    "    print(f\"  Situao: {extract_situacao(sample_text)}\")\n",
    "    \n",
    "    print(\"\\n Sample text for reference:\")\n",
    "    print(sample_text[:300] + \"...\" if len(sample_text) > 300 else sample_text)\n",
    "else:\n",
    "    print(\" No text available for regex testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9b7d2",
   "metadata": {},
   "source": [
    "## 6. Named Entity Recognition with spaCy\n",
    "\n",
    "Let's use spaCy's Portuguese model to identify named entities in our text, which can complement our regex-based extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84a1fa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Portuguese spaCy model loaded successfully!\n",
      " Named entities found:\n",
      "  ORG:\n",
      "    - 'CONSELHO SECCIONAL' (pos: 65-83)\n",
      "  LOC:\n",
      "    - 'Endereo Profissional\n",
      "AVENIDA PAULISTA' (pos: 105-143)\n",
      "    - 'Pilotis' (pos: 159-166)\n",
      "    - 'Bela Vista\n",
      "' (pos: 168-179)\n",
      "    - 'SP' (pos: 191-193)\n",
      "  MISC:\n",
      "    - 'LUIS FILIPE' (pos: 0-11)\n",
      "    - 'ARAUJO AMARAL\n",
      "Inscrio\n",
      "Seccional\n",
      "Subseo' (pos: 12-54)\n",
      "    - 'N 2300' (pos: 145-152)\n",
      "    - 'Telefone Profissional\n",
      "SITUAO REGULAR\n",
      "' (pos: 203-242)\n",
      "\n",
      " When to use NER vs Regex:\n",
      "   NER is better for: Person names, organizations, locations, dates\n",
      "   Regex is better for: Specific formats (phone, ID numbers), structured patterns\n",
      "   Combine both: Use NER for context, regex for precise extraction\n"
     ]
    }
   ],
   "source": [
    "# Load Portuguese spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "    print(\" Portuguese spaCy model loaded successfully!\")\n",
    "except OSError:\n",
    "    print(\" Portuguese spaCy model not found. Trying to use a basic model...\")\n",
    "    try:\n",
    "        nlp = spacy.blank(\"pt\")\n",
    "        print(\" Using blank Portuguese model (limited NER capabilities)\")\n",
    "    except:\n",
    "        nlp = None\n",
    "        print(\" Could not load any spaCy model\")\n",
    "\n",
    "def extract_entities_spacy(text: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Extract named entities using spaCy.\"\"\"\n",
    "    \n",
    "    if not nlp:\n",
    "        return {\"error\": \"spaCy model not available\"}\n",
    "    \n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        entities = {\n",
    "            \"PER\": [], # PERSON\n",
    "            \"ORG\": [], # Organizations\n",
    "            \"LOC\": [], # Locations (\"Endereo Profissional\")\n",
    "            \"MISC\": []\n",
    "        }\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            label = ent.label_\n",
    "            if label in entities:\n",
    "                entities[label].append({\n",
    "                    \"text\": ent.text,\n",
    "                    \"start\": ent.start_char,\n",
    "                    \"end\": ent.end_char,\n",
    "                    \"confidence\": getattr(ent, 'conf', None)\n",
    "                })\n",
    "            else:\n",
    "                entities[\"MISC\"].append({\n",
    "                    \"text\": ent.text,\n",
    "                    \"label\": label,\n",
    "                    \"start\": ent.start_char,\n",
    "                    \"end\": ent.end_char\n",
    "                })\n",
    "        \n",
    "        return entities\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error in spaCy processing: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Extract text from \"oab_2.pdf\" using PyMuPDF\n",
    "fitz_result = extract_text_pymupdf('./files/oab_2.pdf')\n",
    "sample_text = fitz_result.get(\"text\", \"\") if \"error\" not in fitz_result else \"\"\n",
    "# Test NER on our sample text\n",
    "if sample_text and nlp:\n",
    "    entities_result = extract_entities_spacy(sample_text)\n",
    "    \n",
    "    if \"error\" not in entities_result:\n",
    "        print(\" Named entities found:\")\n",
    "        for entity_type, entities in entities_result.items():\n",
    "            if entities:\n",
    "                print(f\"  {entity_type}:\")\n",
    "                for entity in entities:\n",
    "                    print(f\"    - '{entity['text']}' (pos: {entity['start']}-{entity['end']})\")\n",
    "        \n",
    "        print(\"\\n When to use NER vs Regex:\")\n",
    "        print(\"   NER is better for: Person names, organizations, locations, dates\")\n",
    "        print(\"   Regex is better for: Specific formats (phone, ID numbers), structured patterns\")\n",
    "        print(\"   Combine both: Use NER for context, regex for precise extraction\")\n",
    "    else:\n",
    "        print(f\" {entities_result['error']}\")\n",
    "else:\n",
    "    print(\" Skipping NER demonstration (no text or spaCy model available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56c402a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "Consulta de Cobrana\n",
      ", MISC\n",
      "-------\n",
      "Sistema:\n",
      "Contrato:\n",
      ", MISC\n",
      "-------\n",
      "CLIENTE\n",
      "CPF\n",
      ", MISC\n",
      "-------\n",
      "Operao Selecionada\n",
      "Sistema\n",
      "CONSIGNADO\n",
      "VIr, MISC\n",
      "-------\n",
      "Parc, PER\n",
      "-------\n",
      "Cidade, LOC\n",
      "-------\n",
      "Mozarlndia, LOC\n",
      "-------\n",
      "GO CEP, MISC\n",
      "-------\n",
      "Contato\n",
      ", MISC\n",
      "-------\n",
      "Negativado, PER\n",
      "-------\n",
      "SPC, PER\n",
      "-------\n",
      "Status Jurdico\n",
      ", PER\n"
     ]
    }
   ],
   "source": [
    "# faa um exemplo de extrao de labels usando spacy\n",
    "text = \"\"\"Consulta de Cobrana\n",
    "Pesquisar por:\n",
    "Tipo:\n",
    "Sistema:\n",
    "Contrato:\n",
    "Todos\n",
    "Todos\n",
    "V\n",
    "Buscar\n",
    "CLIENTE\n",
    "CPF\n",
    "Operao Selecionada\n",
    "Sistema\n",
    "CONSIGNADO\n",
    "VIr. Parc.\n",
    "2.372,64\n",
    "Cidade: Mozarlndia U.F .: GO CEP: 76709970\n",
    "Dados para Contato\n",
    "Resumo\n",
    "Cobradora\n",
    "Nenhuma\n",
    "Telefone da\n",
    "Nenhum\n",
    "Cobradora\n",
    "Negativado SERASA?\n",
    "No\n",
    "Negativado SPC?\n",
    "No\n",
    "Status Jurdico\n",
    "Nenhum\n",
    "Status Notificao\n",
    "Nenhum\n",
    "\"\"\"\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(\"-------\")\n",
    "    label = ent.ents[0].label_\n",
    "    print(f\"{ent.text}, {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828319a",
   "metadata": {},
   "source": [
    "## 7. Result Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f844ffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid': False, 'data': {'telefone_profissional': None, 'foo': 'bar'}, 'errors': ['unexpected keys: foo']}\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def validate_extraction_result_simple(schema: Dict[str, str], extracted: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simples: garante que s existam as chaves do schema (preenche faltantes com None),\n",
    "    Lista chaves extras.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    validated = {}\n",
    "\n",
    "    # mantm s as chaves do schema (faltantes -> None)\n",
    "    for key in schema:\n",
    "        val = extracted.get(key)\n",
    "        if val is None:\n",
    "            validated[key] = None\n",
    "\n",
    "    # detecta chaves inesperadas e anexa (opcional)\n",
    "    extras = {k: v for k, v in extracted.items() if k not in schema}\n",
    "    if extras:\n",
    "        errors.append(f\"unexpected keys: {', '.join(extras.keys())}\")\n",
    "        validated.update(extras)\n",
    "\n",
    "    return {\"valid\": not errors, \"data\": validated, \"errors\": errors}\n",
    "\n",
    "# --- exemplo de uso ---\n",
    "if __name__ == \"__main__\":\n",
    "    schema = {\n",
    "        \"nome\": \"Nome do advogado\",\n",
    "        \"inscricao\": \"Nmero de inscrio\",\n",
    "        \"seccional\": \"Seccional\",\n",
    "        \"telefone_profissional\": \"Telefone\"\n",
    "    }\n",
    "\n",
    "    example_data = {\n",
    "        \"nome\": \"JOO DA SILVA SANTOS\",\n",
    "        \"inscricao\": 12345,                # inteiro -> ser convertido\n",
    "        \"seccional\": \"SP\",\n",
    "        \"telefone_profissional\": None,\n",
    "        \"foo\": \"bar\"                       # chave extra\n",
    "    }\n",
    "\n",
    "    res = validate_extraction_result_simple(schema, example_data)\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "60fda945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linha 1\n",
      "Linha 2\n",
      "Linha 3\n"
     ]
    }
   ],
   "source": [
    "elements_data = [\n",
    "    {'text': \"JOANA D'ARC\", 'x': 100, 'y': 50},\n",
    "    {'text': \"Inscrio\", 'x': 50, 'y': 100},\n",
    "    {'text': \"Seccional\", 'x': 200, 'y': 100},\n",
    "    {'text': \"Subseo\", 'x': 350, 'y': 100},\n",
    "    {'text': \"101943\", 'x': 50, 'y': 130},\n",
    "    {'text': \"PR\", 'x': 200, 'y': 130},\n",
    "    {'text': \"CONSELHO SECCIONAL - PARAN\", 'x': 350, 'y': 130},\n",
    "    {'text': \"SUPLEMENTAR\", 'x': 100, 'y': 180},\n",
    "    {'text': \"Endereo Profissional\", 'x': 50, 'y': 230},\n",
    "    {'text': \"AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista\", 'x': 50, 'y': 260},\n",
    "    {'text': \"SO PAULO - SP\", 'x': 50, 'y': 290},\n",
    "    {'text': \"01310300\", 'x': 50, 'y': 320},\n",
    "    {'text': \"Telefone Profissional\", 'x': 50, 'y': 350},\n",
    "    {'text': \"SITUAO REGULAR\", 'x': 100, 'y': 450}]\n",
    "\n",
    "\n",
    "elements_data = [\n",
    "        {'text': \"Linha 3\", 'x': 0, 'y': 300},\n",
    "        {'text': \"Linha 1\", 'x': 0, 'y': 100},\n",
    "        {'text': \"Linha 2\", 'x': 0, 'y': 200},]\n",
    "\n",
    "elements_data.sort(key=lambda e: (e['y'], e['x']))\n",
    "\n",
    "# Agrupar em linhas com tolerncia para pequenas diferenas em y\n",
    "final_lines = []\n",
    "current_line = []\n",
    "line_ref_y = None\n",
    "y_tolerance = 5  # Tolerncia em unidades de coordenada\n",
    "\n",
    "for elem in elements_data:\n",
    "    if not all(k in elem for k in ('text', 'x', 'y')):\n",
    "        raise ValueError(\"Elemento invlido: faltando 'text', 'x' ou 'y' chave.\")\n",
    "    if line_ref_y is None:\n",
    "        # inicia primeira linha\n",
    "        current_line.append(elem)\n",
    "        line_ref_y = elem['y']\n",
    "    else:\n",
    "        # compara com o y do primeiro elemento da linha atual\n",
    "        if abs(elem['y'] - line_ref_y) <= y_tolerance:\n",
    "            current_line.append(elem)\n",
    "        else:\n",
    "            # Finalizar linha atual e comear nova\n",
    "            current_line_sorted = sorted(current_line, key=lambda elem: elem['x'])\n",
    "            line_text = \" \".join([e['text'] for e in current_line_sorted])\n",
    "            final_lines.append(line_text)\n",
    "            # Comear nova linha\n",
    "            current_line = [elem]\n",
    "            line_ref_y = elem['y']\n",
    "\n",
    "# Adicionar ltima linha\n",
    "if current_line:\n",
    "    current_line_sorted = sorted(current_line, key=lambda elem: elem['x'])\n",
    "    line_text = \" \".join([e['text'] for e in current_line_sorted])\n",
    "    final_lines.append(line_text)\n",
    "print (\"\\n\".join(final_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b0db475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signature(self, elements: List[Dict[str, Any]]) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extrai a assinatura estrutural de uma lista de elementos do unstructured.\n",
    "    \n",
    "    Esta verso  mais criteriosa e s adiciona no mximo UMA nova assinatura\n",
    "    que no esteja em self.known_labels. A estratgia :\n",
    "    - Manter adio imediata de rtulos conhecidos e ttulos.\n",
    "    - Coletar candidatos que passem heursticas estritas.\n",
    "    - Atribuir uma pontuao a cada candidato com base em sinais fortes de rtulo\n",
    "        (dois-pontos, presena de palavras-chaves, curta extenso, ausncia de\n",
    "        nmeros, categoria etc.).\n",
    "    - Selecionar o melhor candidato (se atingir threshold) e adicion-lo  no\n",
    "        mximo um novo rtulo.\n",
    "    \n",
    "    Args:\n",
    "        elements: Lista de elementos extrados pelo unstructured\n",
    "        \n",
    "    Returns:\n",
    "        Conjunto de rtulos que compem a assinatura estrutural\n",
    "    \"\"\"\n",
    "    signature: Set[str] = set()\n",
    "    candidates: List[Tuple[str, float]] = []  # (label, score)\n",
    "    def token_similarity(a: str, b: str) -> float:\n",
    "        ta = set(a.split())\n",
    "        tb = set(b.split())\n",
    "        if not ta and not tb:\n",
    "            return 0.0\n",
    "        inter = ta.intersection(tb)\n",
    "        uni = ta.union(tb)\n",
    "        return len(inter) / len(uni)\n",
    "\n",
    "    for elem in elements:\n",
    "        text = elem.get('text', '').strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        normalized_text = self._normalize_text(text)\n",
    "\n",
    "        # Regra 1: Rtulo conhecido -> adiciona sem contagem ao limite de 1 novo rtulo\n",
    "        if normalized_text in self.known_labels:\n",
    "            signature.add(normalized_text)\n",
    "            continue\n",
    "\n",
    "        # Evitar valores puramente numricos ou monetrios\n",
    "        if re.fullmatch(r'[\\d\\.,\\-\\/R\\$ %]+', text):\n",
    "            continue\n",
    "\n",
    "        # Evitar sentenas longas (rtulos so geralmente curtos)\n",
    "        if len(normalized_text.split()) > 4:\n",
    "            continue\n",
    "\n",
    "        # Heursticas adicionais para filtrar rudo\n",
    "        if not (2 <= len(normalized_text) <= 50):\n",
    "            continue\n",
    "\n",
    "        # Evitar textos que contenham muitas cifras/ dgitos\n",
    "        if sum(c.isdigit() for c in normalized_text) / max(1, len(normalized_text)) > 0.2:\n",
    "            continue\n",
    "\n",
    "        # Evitar se muito semelhante a um rtulo j presente\n",
    "        too_similar = False\n",
    "        for s in signature:\n",
    "            if token_similarity(normalized_text, s) > 0.75:\n",
    "                too_similar = True\n",
    "                break\n",
    "        if too_similar:\n",
    "            continue\n",
    "\n",
    "        # Se possui \":\", adiciona sem contagem ao limite de 1 novo rtulo\n",
    "        if re.search(r':\\s*$', text):\n",
    "            signature.add(normalized_text)\n",
    "            continue\n",
    "\n",
    "        # Score heurstico para priorizar o melhor candidato\n",
    "        category = elem.get('category', '')\n",
    "        score = 0.0\n",
    "\n",
    "        # Palavra-chave do domnio (aumenta confiana)\n",
    "        domain_keywords = ['nome', 'endereco', 'telefone', 'cpf', 'cnpj', 'email', 'valor', 'data', 'vencimento', 'total', 'subtotal']\n",
    "        for kw in domain_keywords:\n",
    "            if kw in normalized_text:\n",
    "                score += 2.0\n",
    "\n",
    "        # Preferir textos curtos (1-3 tokens)\n",
    "        tokens = normalized_text.split()\n",
    "        if len(tokens) == 1:\n",
    "            score += 1.2\n",
    "        elif len(tokens) <= 3:\n",
    "            score += 0.8\n",
    "\n",
    "        # Penalizar presena de dgitos (provvel valor)\n",
    "        if re.search(r'\\d', normalized_text):\n",
    "            score -= 2.0\n",
    "\n",
    "        # Penalizar se contm palavras muito comuns sem sentido (stopwords simples)\n",
    "        stopwords = {'de', 'do', 'da', 'dos', 'das', 'e', 'ou', 'para', 'com', 'em', 'por'}\n",
    "        stopword_ratio = sum(1 for t in tokens if t in stopwords) / max(1, len(tokens))\n",
    "        if stopword_ratio > 0.5:\n",
    "            score -= 1.0\n",
    "\n",
    "        # Leve bnus se categoria sinalizou algo mas no foi Title\n",
    "        if category:\n",
    "            score += 0.3\n",
    "\n",
    "        # S considerar candidatos com score razovel\n",
    "        if score > 0.0:\n",
    "            candidates.append((normalized_text, score))\n",
    "\n",
    "    # Seleciona o melhor candidato (mximo 1 novo rtulo)\n",
    "    if candidates:\n",
    "        # Ordena por score desc e por comprimento asc para desempate\n",
    "        candidates.sort(key=lambda x: (-x[1], len(x[0])))\n",
    "        best_label, best_score = candidates[0]\n",
    "\n",
    "        # Threshold conservador para aceitar um novo rtulo\n",
    "        if best_score >= 1.5:\n",
    "            # Evitar duplicatas contra known_labels (por segurana)\n",
    "            if best_label not in self.known_labels and best_label not in signature:\n",
    "                signature.add(best_label)\n",
    "\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3c841d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'situacao regular', \"joana d'arc\", 'suplementar', 'telefone profissional', 'endereco profissional', 'inscricao seccional subsecao', 'sao paulo - sp'}\n"
     ]
    }
   ],
   "source": [
    "from core.learning.struct_matcher import StructuralMatcher\n",
    "# testar extract_signature\n",
    "matcher = StructuralMatcher()\n",
    "text = \"\"\"JOANA D'ARC\n",
    "Inscrio Seccional Subseo\n",
    "101943 PR CONSELHO SECCIONAL - PARAN\n",
    "SUPLEMENTAR\n",
    "Endereo Profissional\n",
    "AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista\n",
    "SO PAULO - SP\n",
    "01310300\n",
    "Telefone Profissional\n",
    "SITUAO REGULAR\"\"\"\n",
    "\n",
    "elements = [{'text': line, 'x': 0, 'y': i*10} for i, line in enumerate(text.split('\\n'))]\n",
    "signature = matcher.extract_signature(elements)\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8e800581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"JOANA D'ARC\", 'x': 0, 'y': 0},\n",
       " {'text': 'Inscrio Seccional Subseo', 'x': 0, 'y': 10},\n",
       " {'text': '101943 PR CONSELHO SECCIONAL - PARAN', 'x': 0, 'y': 20},\n",
       " {'text': 'SUPLEMENTAR', 'x': 0, 'y': 30},\n",
       " {'text': 'Endereo Profissional', 'x': 0, 'y': 40},\n",
       " {'text': 'AVENIDA PAULISTA, N 2300 andar Pilotis, Bela Vista',\n",
       "  'x': 0,\n",
       "  'y': 50},\n",
       " {'text': 'SO PAULO - SP', 'x': 0, 'y': 60},\n",
       " {'text': '01310300', 'x': 0, 'y': 70},\n",
       " {'text': 'Telefone Profissional', 'x': 0, 'y': 80},\n",
       " {'text': 'SITUAO REGULAR', 'x': 0, 'y': 90}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b326f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'endereco profissional'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_signature(matcher, elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4d8faa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste: oab_1\n",
      "Regra aprendida para 'nome': Tipo: regex, Dados: {'pattern': 'texto', 'regex': '.+'}, Confiana: 0.7\n",
      "--------------------------------------------------\n",
      "Teste: oab_2\n",
      "Regra aprendida para 'nome': Tipo: regex, Dados: {'pattern': 'texto', 'regex': '.+'}, Confiana: 0.7\n",
      "--------------------------------------------------\n",
      "Teste: oab_3\n",
      "Regra aprendida para 'nome': Tipo: regex, Dados: {'pattern': 'texto', 'regex': '.+'}, Confiana: 0.7\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data = {\n",
    "            \"oab_1\": {\n",
    "                \"expected\": {\n",
    "                    \"nome\": \"JOANA D'ARC\",\n",
    "                    \"inscricao\": \"101943\",\n",
    "                    \"seccional\": \"PR\",\n",
    "                    \"subsecao\": \"Conselho Seccional - Paran\",\n",
    "                    \"categoria\": \"Suplementar\",\n",
    "                    \"endereco_profissional\": \"Avenida Paulista, N 2300, andar Pilotis, Bela Vista, So Paulo - SP, 01310300\",\n",
    "                    \"situacao\": \"Situao Regular\"\n",
    "                },\n",
    "                \"pdf_path\": \"files/oab_1.pdf\"\n",
    "            },\n",
    "            \"oab_2\": {\n",
    "                \"expected\": {\n",
    "                    \"nome\": \"LUIS FILIPE ARAUJO AMARAL\",\n",
    "                    \"inscricao\": \"101943\",\n",
    "                    \"seccional\": \"PR\",\n",
    "                    \"subsecao\": \"Conselho Seccional - Paran\",\n",
    "                    \"categoria\": \"Suplementar\",\n",
    "                    \"endereco_profissional\": None,\n",
    "                    \"situacao\": \"Situao Regular\"\n",
    "                },\n",
    "                \"pdf_path\": \"files/oab_2.pdf\"\n",
    "            },\n",
    "            \"oab_3\": {\n",
    "                \"expected\": {\n",
    "                    \"nome\": \"SON GOKU\",\n",
    "                    \"inscricao\": \"101943\",\n",
    "                    \"seccional\": \"PR\",\n",
    "                    \"subsecao\": \"Conselho Seccional - Paran\",\n",
    "                    \"categoria\": \"Suplementar\",\n",
    "                    \"endereco_profissional\": None,\n",
    "                    \"situacao\": \"Situao Regular\"\n",
    "                },\n",
    "                \"pdf_path\": \"files/oab_3.pdf\"\n",
    "            }\n",
    "        }\n",
    "# import llm connector\n",
    "import os\n",
    "import sys\n",
    "from core.connectors.llm_connector import LLMConnector\n",
    "from core.learning.pattern_builder import PatternBuilder\n",
    "from typing import List, Dict, Any\n",
    "connector = LLMConnector()\n",
    "pb = PatternBuilder()\n",
    "def _get_elements_from_pdf(pdf_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extrai elementos estruturados de um PDF usando o LLMConnector.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Caminho para o arquivo PDF\n",
    "        \n",
    "    Returns:\n",
    "        Lista de elementos com texto e coordenadas\n",
    "    \"\"\"\n",
    "    # Usar mtodos internos do LLMConnector para extrair elementos\n",
    "    raw_elements = connector._parse_pdf_elements(pdf_path)\n",
    "    \n",
    "    # Converter para formato esperado pelo PatternBuilder\n",
    "    elements = []\n",
    "    for elem in raw_elements:\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            continue\n",
    "            \n",
    "        # Extrair coordenadas dos metadados\n",
    "        x, y = 0, 0\n",
    "        if hasattr(elem, 'metadata') and elem.metadata:\n",
    "            coordinates = getattr(elem.metadata, 'coordinates', None)\n",
    "            if coordinates and hasattr(coordinates, 'points'):\n",
    "                if coordinates.points:\n",
    "                    point = coordinates.points[0]\n",
    "                    if isinstance(point, (tuple, list)) and len(point) >= 2:\n",
    "                        x, y = point[0], point[1]\n",
    "                    elif hasattr(point, 'x') and hasattr(point, 'y'):\n",
    "                        x, y = point.x, point.y\n",
    "        \n",
    "        elements.append({\n",
    "            \"text\": elem.text.strip(),\n",
    "            \"x\": x,\n",
    "            \"y\": y\n",
    "        })\n",
    "    \n",
    "    return elements\n",
    "\n",
    "for test_name, test_data in test_data.items():\n",
    "        \n",
    "    elements = _get_elements_from_pdf(test_data[\"pdf_path\"])\n",
    "    nome = test_data[\"expected\"][\"nome\"]\n",
    "    \n",
    "    rule_type, rule_data, confidence = pb.learn_rule_for_field(\"nome\", nome, elements)\n",
    "    print(f\"Teste: {test_name}\")\n",
    "    print(f\"Regra aprendida para 'nome': Tipo: {rule_type}, Dados: {rule_data}, Confiana: {confidence}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
